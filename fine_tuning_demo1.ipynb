{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1izNcVM_yWTHrMFBLK5pGfxZHN9U_XiVm",
      "authorship_tag": "ABX9TyM5rScXE8/1ciOaErB/P9fn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masaki-maroonmaroon-org/misc/blob/main/fine_tuning_demo1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BjH6SWvzgTgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a504617-01a2-4482-8d0d-8de50b19110d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOmA-c5zM76Z",
        "outputId": "f0eda0e0-96ac-4f6d-e9ad-0f2d9a83039c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "files = glob.glob(\"drive/MyDrive/*\")\n",
        "for file in files:\n",
        "  print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAHg_l8LNiDE",
        "outputId": "77547cdd-ebf1-4438-a518-f471b9c9e90c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/jsbackup\n",
            "drive/MyDrive/BUFFALO_みまもり合図\n",
            "drive/MyDrive/FinalHE_v1.92_win32.zip (Unzipped Files)\n",
            "drive/MyDrive/電気_月別グラフデータ.csv\n",
            "drive/MyDrive/無題のスプレッドシート (1).gsheet\n",
            "drive/MyDrive/app-release-unsigned.apk\n",
            "drive/MyDrive/無題のフォーム.gform\n",
            "drive/MyDrive/無題のドキュメント.gdoc\n",
            "drive/MyDrive/無題のスプレッドシート.gsheet\n",
            "drive/MyDrive/Colab Notebooks\n",
            "drive/MyDrive/data.json\n",
            "drive/MyDrive/data_prepared.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f \"drive/MyDrive/data.json\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lSy7pzAinY2",
        "outputId": "76d7d69c-4442-4095-e830-e2a6724315b6"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your JSON file appears to be in a JSONL format. Your file will be converted to JSONL format\n",
            "- Your file contains 661 prompt-completion pairs\n",
            "- More than a third of your `prompt` column/key is uppercase. Uppercase prompts tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "- More than a third of your `completion` column/key is uppercase. Uppercase completions tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `JSON` will be converted to `JSONL`\n",
            "- [Recommended] Lowercase all your data in column/key `prompt` [Y/n]: Y\n",
            "- [Recommended] Lowercase all your data in column/key `completion` [Y/n]: Y\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: Y\n",
            "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: Y\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: Y\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
            "\n",
            "Wrote modified file to `drive/MyDrive/data_prepared.jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"drive/MyDrive/data_prepared.jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 11.52 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "!openai api fine_tunes.create -t \"drive/MyDrive/data_prepared.jsonl\" -m ada"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxmcMip_ulp2",
        "outputId": "f80bca9f-1d4e-42cb-cba0-2819037ce199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found potentially duplicated files with name 'data_prepared.jsonl', purpose 'fine-tune' and size 237193 bytes\n",
            "file-efLM9IW6QnDj47qsftl9MD75\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-ZOnh7Kze0bqGhTHCfqi6Zlrn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqM52kueUcaV",
        "outputId": "7bba7a1b-4cc1-498a-a75f-463611051e79"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: openai: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api completions.create -m  ada:ft-personal-2023-05-29-13-55-44 -p 児童扶養手当の現況届\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW5nfp0Mz4K2",
        "outputId": "42208f15-fdd4-401b-fc73-974810ede590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "児童扶養手当の現況届が提出しています。  「児"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "!openai api fine_tunes.create -t \"data_prepared.jsonl\" -m \"curie\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8oQKS231sr_",
        "outputId": "94e6e2f3-7179-4ce0-e006-cb05cb69787e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found potentially duplicated files with name 'data_prepared.jsonl', purpose 'fine-tune' and size 235643 bytes\n",
            "file-bWnaM3VigN0AgKoHtC0ry6u2\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-WFh4VafI3qBRNDMLOSDoRHR1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb5Cv1qo599W",
        "outputId": "2bf3a953-fd37-44a1-ed9b-c760709aaafd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mError:\u001b[0m No API key provided. You can set your API key in code using 'openai.api_key = <API-KEY>', or you can set the environment variable OPENAI_API_KEY=<API-KEY>). If your API key is stored in a file, you can point the openai module at it with 'openai.api_key_path = <PATH>'. You can generate API keys in the OpenAI web interface. See https://platform.openai.com/account/api-keys for details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "!openai api fine_tunes.follow -i ft-WFh4VafI3qBRNDMLOSDoRHR1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJrsdVec8AuS",
        "outputId": "b0dbefbe-e1f3-42b1-bec0-79944512d0d6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-05-29 14:24:40] Created fine-tune: ft-WFh4VafI3qBRNDMLOSDoRHR1\n",
            "[2023-05-29 14:25:37] Fine-tune costs $1.46\n",
            "[2023-05-29 14:25:38] Fine-tune enqueued. Queue number: 0\n",
            "[2023-05-29 14:25:39] Fine-tune started\n",
            "[2023-05-29 14:28:50] Completed epoch 1/4\n",
            "[2023-05-29 14:30:56] Completed epoch 2/4\n",
            "[2023-05-29 14:33:02] Completed epoch 3/4\n",
            "[2023-05-29 14:35:07] Completed epoch 4/4\n",
            "[2023-05-29 14:35:27] Uploaded model: curie:ft-personal-2023-05-29-14-35-27\n",
            "[2023-05-29 14:35:28] Uploaded result file: file-ewjIOZY2W8UVjwpnnOfpmKj6\n",
            "[2023-05-29 14:35:28] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m curie:ft-personal-2023-05-29-14-35-27 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api completions.create -m curie:ft-personal-2023-05-29-14-35-27 -p \"児童扶養手当の現況届\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZXvUGUz8KGN",
        "outputId": "ef81c8dc-da9b-486a-df93-7be4c6ea94e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "児童扶養手当の現況届を、保護者の自己納"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "completion = openai.Completion.create(\n",
        "    model=\"davinci\",\n",
        "    prompt=\"母子手帳を受け取りたいのですが、手続きを教えてください。\")\n",
        "print(\"davinciの答え：\" + completion.choices[0].text)\n",
        "\n",
        "completion = openai.Completion.create(\n",
        "    model=\"ada:ft-personal-2023-05-29-13-55-44\",\n",
        "    prompt=\"母子手帳を受け取りたいのですが、手続きを教えてください。\")\n",
        "print(\"adaの答え：\" + completion.choices[0].text)\n",
        "\n",
        "completion = openai.Completion.create(\n",
        "    model=\"curie:ft-personal-2023-05-29-14-35-27\",\n",
        "    prompt=\"母子手帳を受け取りたいのですが、手続きを教えてください。\")\n",
        "print(\"curieの答え：\" + completion.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK1Q50BF8jH6",
        "outputId": "5bd87551-3ee2-43f2-f3f0-bc68d4be955b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "davinciの答え：」という質問が寄せら\n",
            "adaの答え：自己負担（\n",
            "curieの答え： -> 母子手帳の受け取\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api models.delete -i \"ada:ft-personal-2023-05-29-13-55-44\"\n",
        "!openai api models.delete -i \"curie:ft-personal-2023-05-29-14-35-27\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TryQeCf9U_4A",
        "outputId": "c2ad6ca1-9336-47e6-a262-86ca761ca9ac"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mError:\u001b[0m The model 'ada:ft-personal-2023-05-29-13-55-44' does not exist (HTTP status code: 404)\n",
            "\u001b[91mError:\u001b[0m The model 'curie:ft-personal-2023-05-29-14-35-27' does not exist (HTTP status code: 404)\n"
          ]
        }
      ]
    }
  ]
}