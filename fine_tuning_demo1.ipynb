{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1aNCsABI96L0JppXMmzNX2WxbdiVmdQMV",
      "authorship_tag": "ABX9TyN8s8gLT0s4tU4CdWBAflXd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/masaki-maroonmaroon-org/misc/blob/main/fine_tuning_demo1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjH6SWvzgTgY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b63f162-46d4-409f-d4d4-e734147e28b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOmA-c5zM76Z",
        "outputId": "44c88332-6736-468a-ceb0-44066da98f90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "files = glob.glob(\"drive/MyDrive/*\")\n",
        "for file in files:\n",
        "  print(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAHg_l8LNiDE",
        "outputId": "0136f613-f0b1-4ef1-b209-5d9400aab35f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive/MyDrive/jsbackup\n",
            "drive/MyDrive/BUFFALO_みまもり合図\n",
            "drive/MyDrive/FinalHE_v1.92_win32.zip (Unzipped Files)\n",
            "drive/MyDrive/電気_月別グラフデータ.csv\n",
            "drive/MyDrive/無題のスプレッドシート (1).gsheet\n",
            "drive/MyDrive/app-release-unsigned.apk\n",
            "drive/MyDrive/無題のフォーム.gform\n",
            "drive/MyDrive/無題のドキュメント.gdoc\n",
            "drive/MyDrive/無題のスプレッドシート.gsheet\n",
            "drive/MyDrive/Colab Notebooks\n",
            "drive/MyDrive/data.json\n",
            "drive/MyDrive/data_prepared.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai tools fine_tunes.prepare_data -f data.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8lSy7pzAinY2",
        "outputId": "2ee65541-fd95-4c6c-ec6f-f2baf17faddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analyzing...\n",
            "\n",
            "- Your JSON file appears to be in a JSONL format. Your file will be converted to JSONL format\n",
            "- Your file contains 661 prompt-completion pairs\n",
            "- There are 1 duplicated prompt-completion sets. These are rows: [406]\n",
            "- More than a third of your `prompt` column/key is uppercase. Uppercase prompts tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "- More than a third of your `completion` column/key is uppercase. Uppercase completions tends to perform worse than a mixture of case encountered in normal language. We recommend to lower case the data if that makes sense in your domain. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "- Your data does not contain a common separator at the end of your prompts. Having a separator string appended to the end of the prompt makes it clearer to the fine-tuned model where the completion should begin. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples. If you intend to do open-ended generation, then you should leave the prompts empty\n",
            "- Your data does not contain a common ending at the end of your completions. Having a common ending string appended to the end of the completion makes it clearer to the fine-tuned model where the completion should end. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more detail and examples.\n",
            "- The completion should start with a whitespace character (` `). This tends to produce better results due to the tokenization we use. See https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset for more details\n",
            "\n",
            "Based on the analysis we will perform the following actions:\n",
            "- [Necessary] Your format `JSON` will be converted to `JSONL`\n",
            "- [Recommended] Remove 1 duplicate rows [Y/n]: y\n",
            "- [Recommended] Lowercase all your data in column/key `prompt` [Y/n]: y\n",
            "/usr/local/lib/python3.10/dist-packages/openai/validators.py:452: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[column] = x[column].str.lower()\n",
            "- [Recommended] Lowercase all your data in column/key `completion` [Y/n]: y\n",
            "- [Recommended] Add a suffix separator ` ->` to all prompts [Y/n]: y\n",
            "/usr/local/lib/python3.10/dist-packages/openai/validators.py:226: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[\"prompt\"] += suffix\n",
            "- [Recommended] Add a suffix ending `\\n` to all completions [Y/n]: \n",
            "/usr/local/lib/python3.10/dist-packages/openai/validators.py:382: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[\"completion\"] += suffix\n",
            "- [Recommended] Add a whitespace character to the beginning of the completion [Y/n]: y\n",
            "/usr/local/lib/python3.10/dist-packages/openai/validators.py:425: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  x[\"completion\"] = x[\"completion\"].apply(\n",
            "\n",
            "\n",
            "Your data will be written to a new JSONL file. Proceed [Y/n]: y\n",
            "\n",
            "Wrote modified file to `data_prepared (1).jsonl`\n",
            "Feel free to take a look!\n",
            "\n",
            "Now use that file when fine-tuning:\n",
            "> openai api fine_tunes.create -t \"data_prepared (1).jsonl\"\n",
            "\n",
            "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string ` ->` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n\"]` so that the generated texts ends at the expected place.\n",
            "Once your model starts training, it'll approximately take 30.14 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "!openai api fine_tunes.create -t \"data_prepared.jsonl\" -m ada"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxmcMip_ulp2",
        "outputId": "7724b2b2-1ac6-4ede-f391-24f625e1fcfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rUpload progress:   0% 0.00/236k [00:00<?, ?it/s]\rUpload progress: 100% 236k/236k [00:00<00:00, 207Mit/s]\n",
            "Uploaded file from data_prepared.jsonl: file-bWnaM3VigN0AgKoHtC0ry6u2\n",
            "Created fine-tune: ft-ZOnh7Kze0bqGhTHCfqi6Zlrn\n",
            "Streaming events until fine-tuning is complete...\n",
            "\n",
            "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
            "[2023-05-29 20:47:03] Created fine-tune: ft-ZOnh7Kze0bqGhTHCfqi6Zlrn\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-ZOnh7Kze0bqGhTHCfqi6Zlrn\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-ZOnh7Kze0bqGhTHCfqi6Zlrn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aqM52kueUcaV",
        "outputId": "72cd42fa-2671-48d4-efee-2375cdb529bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-05-29 20:47:03] Created fine-tune: ft-ZOnh7Kze0bqGhTHCfqi6Zlrn\n",
            "[2023-05-29 21:06:47] Fine-tune costs $0.19\n",
            "[2023-05-29 21:06:47] Fine-tune enqueued. Queue number: 0\n",
            "[2023-05-29 21:06:50] Fine-tune started\n",
            "[2023-05-29 21:08:43] Completed epoch 1/4\n",
            "\n",
            "Stream interrupted (client disconnected).\n",
            "To resume the stream, run:\n",
            "\n",
            "  openai api fine_tunes.follow -i ft-ZOnh7Kze0bqGhTHCfqi6Zlrn\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api completions.create -m  ada:ft-personal-2023-05-29-13-55-44 -p 児童扶養手当の現況届\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bW5nfp0Mz4K2",
        "outputId": "42208f15-fdd4-401b-fc73-974810ede590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "児童扶養手当の現況届が提出しています。  「児"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['OPENAI_API_KEY'] = \"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\"\n",
        "!openai api fine_tunes.create -t \"data_prepared.jsonl\" -m \"curie\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8oQKS231sr_",
        "outputId": "94e6e2f3-7179-4ce0-e006-cb05cb69787e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found potentially duplicated files with name 'data_prepared.jsonl', purpose 'fine-tune' and size 235643 bytes\n",
            "file-bWnaM3VigN0AgKoHtC0ry6u2\n",
            "Enter file ID to reuse an already uploaded file, or an empty string to upload this file anyway: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-WFh4VafI3qBRNDMLOSDoRHR1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tb5Cv1qo599W",
        "outputId": "b6faefb3-9843-4e2e-c330-dea224ca364f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-05-29 14:24:40] Created fine-tune: ft-WFh4VafI3qBRNDMLOSDoRHR1\n",
            "[2023-05-29 14:25:37] Fine-tune costs $1.46\n",
            "[2023-05-29 14:25:38] Fine-tune enqueued. Queue number: 0\n",
            "[2023-05-29 14:25:39] Fine-tune started\n",
            "[2023-05-29 14:28:50] Completed epoch 1/4\n",
            "[2023-05-29 14:30:56] Completed epoch 2/4\n",
            "[2023-05-29 14:33:02] Completed epoch 3/4\n",
            "[2023-05-29 14:35:07] Completed epoch 4/4\n",
            "[2023-05-29 14:35:27] Uploaded model: curie:ft-personal-2023-05-29-14-35-27\n",
            "[2023-05-29 14:35:28] Uploaded result file: file-ewjIOZY2W8UVjwpnnOfpmKj6\n",
            "[2023-05-29 14:35:28] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m curie:ft-personal-2023-05-29-14-35-27 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api fine_tunes.follow -i ft-WFh4VafI3qBRNDMLOSDoRHR1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJrsdVec8AuS",
        "outputId": "a3946798-18ae-4416-f4f7-4a16c43e990c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2023-05-29 14:24:40] Created fine-tune: ft-WFh4VafI3qBRNDMLOSDoRHR1\n",
            "[2023-05-29 14:25:37] Fine-tune costs $1.46\n",
            "[2023-05-29 14:25:38] Fine-tune enqueued. Queue number: 0\n",
            "[2023-05-29 14:25:39] Fine-tune started\n",
            "[2023-05-29 14:28:50] Completed epoch 1/4\n",
            "[2023-05-29 14:30:56] Completed epoch 2/4\n",
            "[2023-05-29 14:33:02] Completed epoch 3/4\n",
            "[2023-05-29 14:35:07] Completed epoch 4/4\n",
            "[2023-05-29 14:35:27] Uploaded model: curie:ft-personal-2023-05-29-14-35-27\n",
            "[2023-05-29 14:35:28] Uploaded result file: file-ewjIOZY2W8UVjwpnnOfpmKj6\n",
            "[2023-05-29 14:35:28] Fine-tune succeeded\n",
            "\n",
            "Job complete! Status: succeeded 🎉\n",
            "Try out your fine-tuned model:\n",
            "\n",
            "openai api completions.create -m curie:ft-personal-2023-05-29-14-35-27 -p <YOUR_PROMPT>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api completions.create -m curie:ft-personal-2023-05-29-14-35-27 -p \"児童扶養手当の現況届\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZXvUGUz8KGN",
        "outputId": "ef81c8dc-da9b-486a-df93-7be4c6ea94e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "児童扶養手当の現況届を、保護者の自己納"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "\n",
        "completion = openai.Completion.create(\n",
        "    model=\"davinci\",\n",
        "    prompt=\"母子手帳を受け取りたいのですが、手続きを教えてください。\")\n",
        "print(\"davinciの答え：\" + completion.choices[0].text)\n",
        "\n",
        "completion = openai.Completion.create(\n",
        "    model=\"ada:ft-personal-2023-05-29-13-55-44\",\n",
        "    prompt=\"母子手帳を受け取りたいのですが、手続きを教えてください。\")\n",
        "print(\"adaの答え：\" + completion.choices[0].text)\n",
        "\n",
        "completion = openai.Completion.create(\n",
        "    model=\"curie:ft-personal-2023-05-29-14-35-27\",\n",
        "    prompt=\"母子手帳を受け取りたいのですが、手続きを教えてください。\")\n",
        "print(\"curieの答え：\" + completion.choices[0].text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK1Q50BF8jH6",
        "outputId": "5bd87551-3ee2-43f2-f3f0-bc68d4be955b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "davinciの答え：」という質問が寄せら\n",
            "adaの答え：自己負担（\n",
            "curieの答え： -> 母子手帳の受け取\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!openai api models.delete -i \"ada:ft-personal-2023-05-29-13-55-44\"\n",
        "!openai api models.delete -i \"curie:ft-personal-2023-05-29-14-35-27\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TryQeCf9U_4A",
        "outputId": "34dc6dcf-1825-4cea-9927-926e517ce620"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"deleted\": true,\n",
            "  \"id\": \"ada:ft-personal-2023-05-29-13-55-44\",\n",
            "  \"object\": \"model\"\n",
            "}\n",
            "{\n",
            "  \"deleted\": true,\n",
            "  \"id\": \"curie:ft-personal-2023-05-29-14-35-27\",\n",
            "  \"object\": \"model\"\n",
            "}\n"
          ]
        }
      ]
    }
  ]
}